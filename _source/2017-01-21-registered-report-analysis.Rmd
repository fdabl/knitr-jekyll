---
layout: post
title: "Analysis for our Registered Replication of Cohen et al. (2015)"
author: "Fabian Dablander, Katharina Brecht, Lea Jakob, Nicola Clayton"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Introduction
In this document we go through and discuss our planned analysis for our Registered Replication of Cohen et al. (2015). We simulate data according to our hypotheses, and setup R code to automatically analyze the resulting data. Therefore, once we have finished our own data collection, everything is already automated.

```{r}
library('afex')
library('lme4')
library('papaja')
library('tidyverse')
library('BayesFactor')
theme_set(theme_apa())
```

# Simulation setup
Let's simulate data according to our hypotheses. Let 'P' and 'Q' denote our within-subject conditions, i.e., 'truth value' and 'representation (mental vs. non-mental note)', and let 'B' denote our between-subject condition, i.e., 'instruction'.

```{r}
simulate_dat <- function(N, trials) {
  P <- 2
  Q <- 2 ## P, Q: within factors
  B <- 2 # B: between factor
  
  d <- data.frame(
    id = rep(seq(N), each = P*Q*trials),
    trial = rep(seq(trials), each = P*Q),
    B = rep(seq(2) - 1, each = N*trials*P*Q / 2)
  )
  
  i <- 0
  n_total <- N*trials
  within <- expand.grid(P = seq(P), Q = seq(Q)) - 1
  within_mat <- matrix(NA, nrow = n_total, ncol = 2)

  # here we randomly assign the PxQ within conditions
  while (i < n_total) {
    w <- sample(within)
    for (k in seq(4)) {
      for (j in seq(2)) {
        within_mat[k + i, j] <- w[k, j]
      }
    }
    
    i <- i + 4
  }
  
  colnames(within_mat) <- c('P', 'Q')
  cbind(d, within_mat) %>% 
    select(id, trial, P, Q, B)
}

d <- simulate_dat(100, 20) # for computational efficiency, only 100 participants and 20 trials
head(d)
```

Therefore, in the following we assume that there is no main effect of representation on response time and errors, which corresponds to $H_{1a}$ and $H_{1b}$. Additionally, we assume that there is no effect of instruction on representation, i.e., no interaction, which corresponds to our $H_2$.

### Reaction time data
Most frequently, reaction times do not follow a normal distribution. Instead, recent research suggests assuming a Gamma distribution works best [Lo and Andrews (2015)](http://journal.frontiersin.org/article/10.3389/fpsyg.2015.01171/full).
  
The pdf of the Gamma distribution is
$$
f(x; \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1} e^{-\beta x}
$$

with a mean of $\mathbb{E}[X] = \frac{\alpha}{\beta}$ where $\alpha$ is the shape and $\beta$ is the rate parameter. In the simulations, we draw from two Gamma distributions, one with $\alpha = 10, \beta = 1/30$, the other with $\alpha = 9, \beta = 1/30$ such that the mean effect of 'representation' is $300 - 270 = 30$ milliseconds.

### Error data
On each trial, whether the partipant makes an error or not, is modeled as a Bernoulli distribution

$$
f(x; \theta) = \theta^x (1 - \theta)^{1 - x}
$$

where $\theta$ determines the likelihood of an error. For a trial with a mental representation, we assume $\theta = .5$, i.e., random errors, while a non-mental representation should have more errors, say $\theta = .75$.

```{r}
set.seed(1774)

nn <- nrow(d) / 2
dat <- d %>% 
  rename(
    repr = Q,
    truth = P,
    instr = B
  ) %>% 
  mutate(
    RT = ifelse(repr == 0, rgamma(nn, shape = 10, rate = 1/30), rgamma(nn, shape = 9, rate = 1/30)),
    err = ifelse(repr == 0, rbinom(1, n = nn, prob = .75), rbinom(1, n = nn, prob = .5))
  )
```

Before we visualize the simulation results, we have to apply our outlier selection criteria. 

```{r}
datf <- dat %>% 
  filter(
    RT < mean(RT) + 3*sd(RT),
    RT > mean(RT) - 3*sd(RT),
    err < mean(err) + 3*sd(err),
    err > mean(err) - 3*sd(err)
  ) %>% 
  mutate(
    truth = factor(ifelse(truth == 0, 'false', 'true')),
    repr = factor(ifelse(repr == 0, 'non-mental', 'mental')),
    instr = factor(ifelse(instr == 0, 'Old instruction', 'New instruction'))
    )
```

This lead to the removal of
```{r}
((nrow(dat) - nrow(datf)) / nrow(dat)) * 100
```
percent of the data. Additionally, for the reaction time data, we remove trials that the participants got wrong.
```{r}
dat_rt <- filter(datf, err != 1)
```

### Data visualization
```{r}
dat_errm <- datf %>% 
  group_by(repr, truth) %>% 
  summarize(err = mean(err))

dat_rtm <- dat_rt %>% 
  group_by(repr, truth) %>% 
  summarize(meanRT = mean(RT))

dat_errm
dat_rtm
```

Below we plot the data as predicted; averaged across participants.
```{r}
datsum_err <- datf %>% 
  group_by(instr, repr, truth) %>% 
  summarize(err = mean(err))

datsum_rt <- dat_rt %>% 
  group_by(instr, repr, truth) %>% 
  summarize(meanRT = mean(RT))

ggplot(datsum_rt, aes(x = repr, y = meanRT, color = truth)) +
  geom_point() +
  geom_line(aes(group = truth)) +
  facet_wrap(~ instr) +
  ylim(c(200, 300)) +
  xlab('Representation') +
  ylab('Mean RT') +
  ggtitle('Predictions Reaction Time (averaged)') +
  theme(plot.title = element_text(hjust = .5))

ggplot(datsum_err, aes(x = repr, y = err, color = truth)) +
  geom_point() +
  geom_line(aes(group = truth)) +
  facet_wrap(~ instr) +
  ylim(c(0, 1)) +
  xlab('Representation') +
  ylab('Mean % error') +
  ggtitle('Predictions Error rate (averaged)') +
  theme(plot.title = element_text(hjust = .5))
```

Now that we have simulated our data, let's proceed with the planned analysis.

# Data analysis
Note that the data is unbalanced due to our outlier removal, and thus the assumption of ANOVA are violated. While I proceed with focusing on ANOVA based analyses, I recommend the generalized linear mixed model (GLMM) approach. Because GLMMs do not converge easily using classical estimation, I would utilize Stan to estimate it in a Bayesian fashion, and focus on model checking and computing effect sizes based on the fitted model.

Additionally, for the error dependent variable, averaging across participants and computing an ANOVA on percent change is suboptimal. Because errors represent choice data, thus following a Bernoulli distribution, the variance is $\mathrm{Var}[X] = \theta (1 - \theta)$, i.e., not constant for values of $\theta$. This violates homoscedasticity, a crucial assumption of ANOVA [see JÃ¤ger (2008)](http://www.sciencedirect.com/science/article/pii/S0749596X07001337). The figure below makes this apparent. The variance of the groups is only equal should $\theta = .5$, or when they are equidistant from $\theta = .5$, which we cannot know a priori.

```{r}
theta <- seq(0, 1, length.out = 100)
var_bern <- function(theta) theta * (1 - theta)
dat_bern <- data.frame(variance = var_bern(theta), theta = theta)

ggplot(dat_bern, aes(x = theta, y = variance)) +
  geom_line()
```

As apparent on the plot below, the variance of two groups will be equal only when their $\theta$ is the same, or equidistant from $\theta = .5$. Because this cannot be determined a priori, most often homoscedasticity is violated.

Therefore, the optimal model would be a generalized linear mixed model using a Bernoulli link function.


## Bayesian Generalized Linear Mixed Models
As pointed out above, however, reaction times are rarely normally distributed. Therefore, below, we assume a Gamma distribution for reaction times. For the error data, we assume a Bernoulli distribution.

Further, we use a maximal random effects structure as specified by the design (cf., Barr et al., 2013)
```{r}
library('rstanarm')
```

### Reaction time
```{r, eval = FALSE}
m_full <- stan_glmer(RT ~ truth*repr*instr + (truth*repr|id),
                     family = Gamma(link = log), dat = dat_rt,
                     cores = 2, iter = 300, chains = 2)

m_simple <- stan_glmer(RT ~ repr + (truth*repr|id),
                       family = Gamma(link = log), dat = dat_rt,
                       cores = 2, iter = 300, chains = 2)
```

### Errors
```{r, eval = FALSE}
m_full_err <- stan_glmer(err ~ truth*repr*instr + (truth*repr|id),
                         family = binomial(link = 'logit'), dat = datf,
                         cores = 2, iter = 300, chains = 2)

m_simple_err <- stan_glmer(err ~ repr + (truth*repr|id),
                           family = binomial(link = 'logit'), dat = datf,
                           cores = 2, iter = 300, chains = 2)
```

# Appendix
## Frequentist Generalized Linear Mixed models
As pointed out above, however, reaction times are rarely normally distributed. Therefore, below, we assume a Gamma distribution for reaction times. For the error data, we assume a Bernoulli distribution.

Further, we use a maximal random effects structure as specified by the design (cf., Barr et al., 2013)

### Reaction time
```{r, eval = FALSE}
m_rt <- glmer(RT ~ truth*repr*instr + (truth*repr|id), family = Gamma, data = dat_rt)

# correlation between fixed effects is not of interest to us
print(summary(m_rt), correlation = FALSE)
```

### Errors
```{r, eval = FALSE}
m_err <- glmer(err ~ truth*repr*instr + (truth*repr|id), family = binomial, data = datf)

print(summary(m_err), correlation = FALSE)
```

## Frequentist Split-plot ANOVA
### Reaction time
```{r}
m_rt <- aov_car(RT ~ truth*repr*instr + Error(id/(truth*repr)), data = dat_rt)
summary(m_rt)
```

### Errors
```{r}
m_err <- aov_car(err ~ truth*repr*instr + Error(id/(truth*repr)), data = datf)
summary(m_err)
```

## Bayesian Split-plot ANOVA
Below we use the 'BayesFactor' package to compute the Bayes factor for our split-plot ANOVA with 'id' is a
random effect.

### Reaction times
```{r, eval = FALSE}
# Bayes factor package requires factors, not numerical values
datff_rt <- mutate(dat_rt, truth = factor(truth), repr = factor(repr), instr = factor(instr), id = factor(id))
bf_rt <- anovaBF(RT ~ repr*truth*instr + id, whichRandom = 'id', data = datff_rt)

bf_rt
```

Let's find the model with the highest Bayes factor
```{r, eval = FALSE}
max(bf_rt)
```

### Errors
```{r, eval = FALSE}
datff <- mutate(datf, truth = factor(truth), repr = factor(repr), instr = factor(instr), id = factor(id))
bf_err <- anovaBF(err ~ repr*truth*instr + id, whichRandom = 'id', data = datff)

bf_err
```

Let's find the model with the highest Bayes factor
```{r, eval = FALSE}
max(bf_err)
```
